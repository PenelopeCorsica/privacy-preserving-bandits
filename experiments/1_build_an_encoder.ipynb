{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iteround in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: pairing in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (0.1.3)\n",
      "Requirement already satisfied: scikit-multilearn in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (0.2.0)\n",
      "Requirement already satisfied: arff in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (0.9)\n",
      "Requirement already satisfied: category_encoders in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from category_encoders) (0.25.1)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from category_encoders) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from category_encoders) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from category_encoders) (1.17.2)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from category_encoders) (0.10.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=0.21.1->category_encoders) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=0.21.1->category_encoders) (2019.3)\n",
      "Requirement already satisfied: six in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
      "Requirement already satisfied: matplotlib in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (3.1.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib) (1.17.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /Users/moh/.local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: tensorflow in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (1.26.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/moh/.local/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (3.11.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied: gast==0.2.2 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/moh/.local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/moh/.local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: h5py in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/moh/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/moh/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/moh/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/moh/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: h5py in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from keras) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/moh/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from keras) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install iteround\n",
    "!pip install pairing \n",
    "!pip install scikit-multilearn\n",
    "!pip install arff\n",
    "!pip install category_encoders\n",
    "!pip install matplotlib\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRCXMRe-ijVa"
   },
   "outputs": [],
   "source": [
    "## Basics\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import iteround\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy import special\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "class Hasher():\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    os.environ['PYTHONHASHSEED']=str(0)\n",
    "    \"\"\"\n",
    "    comb_algo : \"rec\", \"prod\"\n",
    "    \n",
    "    cluster_algo: \"kmean\", \"mbkmean\"\n",
    "    \"\"\"\n",
    "    def __init__(self, comb_algo = \"rec\", cluster_algo= \"kmean\"):\n",
    "        self.comb_algo = comb_algo\n",
    "        self.cluster_algo = cluster_algo\n",
    "\n",
    "    def combinations_prod(self, n, tot):\n",
    "        #### src: https://codereview.stackexchange.com/questions/190122/permutations-with-a-sum-constraint\n",
    "        def combinations_prod_inner(n, tot):\n",
    "            items = list(range(0,tot+1,1))\n",
    "            combinations = pd.DataFrame(list(filter(lambda x: np.sum(x)==tot, \n",
    "                                                  list(itertools.product(items, repeat=n)))))\n",
    "            return(combinations.as_matrix())\n",
    "\n",
    "        res = combinations_prod_inner(n, tot)\n",
    "        res = np.array(res)\n",
    "        res = res/res.sum(axis=1)[:, np.newaxis]\n",
    "        return res\n",
    "\n",
    "\n",
    "    def combinations_recursive(self, n, tot):\n",
    "        #### src: https://codereview.stackexchange.com/questions/190122/permutations-with-a-sum-constraint\n",
    "        def combinations_recursive_inner(n, buf, gaps, tsum, accum, tot):\n",
    "            if gaps == 0:\n",
    "                accum.append(list(buf))\n",
    "            else:\n",
    "                for x in range(0, tot+1):\n",
    "                    if tsum + x + (gaps - 1) * tot < tot:\n",
    "                        continue\n",
    "                    if tsum + x > tot:\n",
    "                        break\n",
    "                    combinations_recursive_inner(n, buf + [x], gaps - 1, tsum + x, accum, tot)\n",
    "        \n",
    "        res = []\n",
    "        combinations_recursive_inner(n, [], n, 0, res, tot)\n",
    "        res = np.array(res)\n",
    "        res = res/res.sum(axis=1)[:, np.newaxis]\n",
    "        return res\n",
    "\n",
    "    \n",
    "    \n",
    "    def build_hasher(self, context_size, bin_size, dec_digits=1, saving=True):\n",
    "        ### src:https://en.wikipedia.org/wiki/Stars_and_bars_(combinatorics)\n",
    "        num_tot_hsits = special.comb(((10**dec_digits)+context_size-1), context_size-1)\n",
    "        print(\"Total number of possible contexts(histograms):\", num_tot_hsits)\n",
    "        if self.comb_algo == \"rec\":\n",
    "            all_hists = self.combinations_recursive(context_size, 10**dec_digits)\n",
    "        elif self.comb_algo == \"prod\":\n",
    "            all_hists = self.combinations_prod(context_size, 10**dec_digits)\n",
    "        \n",
    "        #### To clustering histograms\n",
    "        print(\"Clustering...\")\n",
    "        if self.cluster_algo == \"kmean\":\n",
    "            kmeans = KMeans(n_clusters=2**bin_size,\n",
    "                            n_jobs = -1,\n",
    "                            random_state=0).fit(all_hists)\n",
    "        elif self.cluster_algo == \"mbkmean\":\n",
    "            kmeans = MiniBatchKMeans(n_clusters=2**bin_size, \n",
    "                                     batch_size = bin_size*bin_size,\n",
    "                                     init_size=2**bin_size,\n",
    "                                     n_init=bin_size,\n",
    "                                     random_state=0).fit(all_hists)\n",
    "        \n",
    "        #### To order clustering labels from highest to lowest\n",
    "        idx = np.argsort(kmeans.cluster_centers_.sum(axis=1))\n",
    "        re_indexer = np.zeros_like(idx)\n",
    "        re_indexer[idx] = np.arange(2**bin_size)\n",
    "        \n",
    "        if saving:\n",
    "            print(\"Saving...\")\n",
    "            save_dir = \"encoders_repo\"\n",
    "            f_name =  \"hasher_\"+str(context_size)+\"_\"+str(dec_digits)+\"_\"+str(bin_size)\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            with open(save_dir+\"/kmeans_\"+f_name+\".pkl\", 'wb') as fid:\n",
    "                pickle.dump(kmeans, fid)\n",
    "            np.save(save_dir+\"/re_indexer_\"+f_name+\".npy\", re_indexer)\n",
    "        \n",
    "        print(\"Completed!\")\n",
    "        return kmeans, re_indexer\n",
    "    \n",
    "    def get_hasher(self, context_size, bin_size, dec_digits=1):\n",
    "        save_dir = \"encoders_repo\"\n",
    "        f_name =  \"hasher_\"+str(context_size)+\"_\"+str(dec_digits)+\"_\"+str(bin_size)\n",
    "        with open(save_dir+\"/kmeans_\"+f_name+\".pkl\", 'rb') as fid:\n",
    "            kmeans = pickle.load(fid)\n",
    "        re_indexer = np.load(save_dir+\"/re_indexer_\"+f_name+\".npy\")\n",
    "        \n",
    "        return kmeans, re_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 301710,
     "status": "error",
     "timestamp": 1567462669458,
     "user": {
      "displayName": "M. M.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBDWyjiBHdeijAV12uYubfUgHbdnQEzBok62Adg=s64",
      "userId": "11054559934326118576"
     },
     "user_tz": -60
    },
    "id": "4hEJ25tMijVc",
    "outputId": "efe4e40b-9b28-4205-a490-6770584691d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of possible contexts(histograms): 92378.0\n",
      "Clustering...\n",
      "Saving...\n",
      "Completed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
       "                 init_size=1024, max_iter=100, max_no_improvement=10,\n",
       "                 n_clusters=1024, n_init=10, random_state=0,\n",
       "                 reassignment_ratio=0.01, tol=0.0, verbose=0),\n",
       " array([175, 664, 665, ..., 373, 829, 868]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## If you don't have a problem with computation resouces and want a bit more accurate encoding use \"cluster_algo = kmean\"\n",
    "hasher = Hasher(comb_algo = \"rec\", cluster_algo= \"mbkmean\")\n",
    "hasher.build_hasher(context_size=10,\n",
    "                    bin_size=10,\n",
    "                    dec_digits=1,\n",
    "                    saving=True)\n",
    "#hasher.get_hasher(context_size, bin_size,dec_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZB81RU1BNpQ"
   },
   "source": [
    "### What is the Next Step?\n",
    "\n",
    "Build as much as **Encoder** you need for your desired `context_size`, `bin_size`, and `dec_digits`. Then you can run one of the following notebooks:\n",
    "* 2_synthetic_exp.ipynb\n",
    "* 2_mlc_exp.ipynb\n",
    "* 2_criteo_exp.ipynb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Build_Hasher.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
