{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRCXMRe-ijVa"
   },
   "outputs": [],
   "source": [
    "## Basics\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import iteround\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy import special\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "class Hasher():\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    os.environ['PYTHONHASHSEED']=str(0)\n",
    "    \"\"\"\n",
    "    comb_algo : \"rec\", \"prod\"\n",
    "    \n",
    "    cluster_algo: \"kmean\", \"mbkmean\"\n",
    "    \"\"\"\n",
    "    def __init__(self, comb_algo = \"rec\", cluster_algo= \"kmean\"):\n",
    "        self.comb_algo = comb_algo\n",
    "        self.cluster_algo = cluster_algo\n",
    "\n",
    "    def combinations_prod(self, n, tot):\n",
    "        #### src: https://codereview.stackexchange.com/questions/190122/permutations-with-a-sum-constraint\n",
    "        def combinations_prod_inner(n, tot):\n",
    "            items = list(range(0,tot+1,1))\n",
    "            combinations = pd.DataFrame(list(filter(lambda x: np.sum(x)==tot, \n",
    "                                                  list(itertools.product(items, repeat=n)))))\n",
    "            return(combinations.as_matrix())\n",
    "\n",
    "        res = combinations_prod_inner(n, tot)\n",
    "        res = np.array(res)\n",
    "        res = res/res.sum(axis=1)[:, np.newaxis]\n",
    "        return res\n",
    "\n",
    "\n",
    "    def combinations_recursive(self, n, tot):\n",
    "        #### src: https://codereview.stackexchange.com/questions/190122/permutations-with-a-sum-constraint\n",
    "        def combinations_recursive_inner(n, buf, gaps, tsum, accum, tot):\n",
    "            if gaps == 0:\n",
    "                accum.append(list(buf))\n",
    "            else:\n",
    "                for x in range(0, tot+1):\n",
    "                    if tsum + x + (gaps - 1) * tot < tot:\n",
    "                        continue\n",
    "                    if tsum + x > tot:\n",
    "                        break\n",
    "                    combinations_recursive_inner(n, buf + [x], gaps - 1, tsum + x, accum, tot)\n",
    "        \n",
    "        res = []\n",
    "        combinations_recursive_inner(n, [], n, 0, res, tot)\n",
    "        res = np.array(res)\n",
    "        res = res/res.sum(axis=1)[:, np.newaxis]\n",
    "        return res\n",
    "\n",
    "    \n",
    "    \n",
    "    def build_hasher(self, context_size, bin_size, dec_digits=1, saving=True):\n",
    "        ### src:https://en.wikipedia.org/wiki/Stars_and_bars_(combinatorics)\n",
    "        num_tot_hsits = special.comb(((10**dec_digits)+context_size-1), context_size-1)\n",
    "        print(\"Total number of possible contexts(histograms):\", num_tot_hsits)\n",
    "        if self.comb_algo == \"rec\":\n",
    "            all_hists = self.combinations_recursive(context_size, 10**dec_digits)\n",
    "        elif self.comb_algo == \"prod\":\n",
    "            all_hists = self.combinations_prod(context_size, 10**dec_digits)\n",
    "        \n",
    "        #### To clustering histograms\n",
    "        print(\"Clustering...\")\n",
    "        if self.cluster_algo == \"kmean\":\n",
    "            kmeans = KMeans(n_clusters=2**bin_size,\n",
    "                            n_jobs = -1,\n",
    "                            random_state=0).fit(all_hists)\n",
    "        elif self.cluster_algo == \"mbkmean\":\n",
    "            kmeans = MiniBatchKMeans(n_clusters=2**bin_size, \n",
    "                                     batch_size = bin_size*bin_size,\n",
    "                                     init_size=2**bin_size,\n",
    "                                     n_init=bin_size,\n",
    "                                     random_state=0).fit(all_hists)\n",
    "        \n",
    "        #### To order clustering labels from highest to lowest\n",
    "        idx = np.argsort(kmeans.cluster_centers_.sum(axis=1))\n",
    "        re_indexer = np.zeros_like(idx)\n",
    "        re_indexer[idx] = np.arange(2**bin_size)\n",
    "        \n",
    "        if saving:\n",
    "            print(\"Saving...\")\n",
    "            save_dir = \"encoders_repo\"\n",
    "            f_name =  \"hasher_\"+str(context_size)+\"_\"+str(dec_digits)+\"_\"+str(bin_size)\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            with open(save_dir+\"/kmeans_\"+f_name+\".pkl\", 'wb') as fid:\n",
    "                pickle.dump(kmeans, fid)\n",
    "            np.save(save_dir+\"/re_indexer_\"+f_name+\".npy\", re_indexer)\n",
    "        \n",
    "        print(\"Completed!\")\n",
    "        return kmeans, re_indexer\n",
    "    \n",
    "    def get_hasher(self, context_size, bin_size, dec_digits=1):\n",
    "        save_dir = \"encoders_repo\"\n",
    "        f_name =  \"hasher_\"+str(context_size)+\"_\"+str(dec_digits)+\"_\"+str(bin_size)\n",
    "        with open(save_dir+\"/kmeans_\"+f_name+\".pkl\", 'rb') as fid:\n",
    "            kmeans = pickle.load(fid)\n",
    "        re_indexer = np.load(save_dir+\"/re_indexer_\"+f_name+\".npy\")\n",
    "        \n",
    "        return kmeans, re_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 301710,
     "status": "error",
     "timestamp": 1567462669458,
     "user": {
      "displayName": "M. M.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBDWyjiBHdeijAV12uYubfUgHbdnQEzBok62Adg=s64",
      "userId": "11054559934326118576"
     },
     "user_tz": -60
    },
    "id": "4hEJ25tMijVc",
    "outputId": "efe4e40b-9b28-4205-a490-6770584691d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of possible contexts(histograms): 92378.0\n",
      "Clustering...\n",
      "Saving...\n",
      "Completed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "        n_clusters=1024, n_init=10, n_jobs=-1, precompute_distances='auto',\n",
       "        random_state=0, tol=0.0001, verbose=0),\n",
       " array([248,  67, 413, ..., 369, 726, 528]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For large numbers you can choose \"mbkmean\"\n",
    "hasher = Hasher(comb_algo = \"rec\", cluster_algo= \"kmean\")\n",
    "hasher.build_hasher(context_size=10,\n",
    "                    bin_size=10,\n",
    "                    dec_digits=1,\n",
    "                    saving=True)\n",
    "#hasher.get_hasher(context_size, bin_size,dec_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZB81RU1BNpQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Build_Hasher.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
